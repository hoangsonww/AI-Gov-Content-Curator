apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: ai-curator
  labels:
    app: backend
spec:
  selector:
    app: backend
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 3000
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  name: backend-canary
  namespace: ai-curator
  labels:
    app: backend
spec:
  selector:
    app: backend
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 3000
  type: ClusterIP
---
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: backend
  namespace: ai-curator
  labels:
    app: backend
spec:
  replicas: 3
  revisionHistoryLimit: 5
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
        - name: backend
          image: ghcr.io/hoangsonww/ai-curator-backend:latest
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          env:
            - name: NODE_ENV
              value: "production"
            - name: PORT
              value: "3000"
          envFrom:
            - secretRef:
                name: backend-secrets
            - configMapRef:
                name: backend-config
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: 1000m
              memory: 2Gi
          livenessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
  strategy:
    canary:
      # Reference to stable service
      stableService: backend
      # Reference to canary service
      canaryService: backend-canary
      # Traffic routing using Istio, Nginx, or ALB
      trafficRouting:
        # Using Istio for traffic management
        istio:
          virtualService:
            name: backend
            routes:
              - primary
        # Alternative: Using Nginx Ingress
        # nginx:
        #   stableIngress: backend
        #   additionalIngressAnnotations:
        #     canary-by-header: X-Canary
        # Alternative: Using AWS ALB
        # alb:
        #   ingress: backend
        #   servicePort: 80
      # Analysis to determine rollout success
      analysis:
        templates:
          - templateName: success-rate
          - templateName: latency
        startingStep: 2
        args:
          - name: service-name
            value: backend
      # Canary deployment steps
      steps:
        # Step 1: Deploy canary with 10% traffic
        - setWeight: 10
        - pause:
            duration: 5m
        # Step 2: Increase to 20% traffic
        - setWeight: 20
        - pause:
            duration: 5m
        # Step 3: Increase to 40% traffic
        - setWeight: 40
        - pause:
            duration: 5m
        # Step 4: Increase to 60% traffic
        - setWeight: 60
        - pause:
            duration: 5m
        # Step 5: Increase to 80% traffic
        - setWeight: 80
        - pause:
            duration: 5m
        # Step 6: Full rollout
        - setWeight: 100
      # Auto-promotion after analysis succeeds
      autoPromotionEnabled: false
      # Auto-promotion after seconds
      autoPromotionSeconds: 300
      # Max unavailable
      maxUnavailable: 1
      # Max surge
      maxSurge: 1
      # Anti-affinity
      antiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution: {}
        preferredDuringSchedulingIgnoredDuringExecution:
          weight: 1
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate
  namespace: ai-curator
spec:
  args:
    - name: service-name
  metrics:
    - name: success-rate
      interval: 1m
      successCondition: result >= 0.95
      failureLimit: 3
      provider:
        prometheus:
          address: http://prometheus.monitoring.svc.cluster.local:9090
          query: |
            sum(rate(
              http_requests_total{
                service="{{args.service-name}}",
                status!~"5.."
              }[5m]
            ))
            /
            sum(rate(
              http_requests_total{
                service="{{args.service-name}}"
              }[5m]
            ))
---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: latency
  namespace: ai-curator
spec:
  args:
    - name: service-name
  metrics:
    - name: latency
      interval: 1m
      successCondition: result < 500
      failureLimit: 3
      provider:
        prometheus:
          address: http://prometheus.monitoring.svc.cluster.local:9090
          query: |
            histogram_quantile(0.95,
              sum(rate(
                http_request_duration_milliseconds_bucket{
                  service="{{args.service-name}}"
                }[5m]
              )) by (le)
            )
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: backend-config
  namespace: ai-curator
data:
  AICC_API_URL: "http://backend.ai-curator.svc.cluster.local"
  AI_INSTRUCTIONS: "Summarize the articles concisely and naturally"
  NODE_ENV: "production"
---
apiVersion: v1
kind: Secret
metadata:
  name: backend-secrets
  namespace: ai-curator
type: Opaque
# Replace with actual values or use external secrets operator
stringData:
  MONGODB_URI: "REPLACE_ME"
  GOOGLE_AI_API_KEY: "REPLACE_ME"
  RESEND_API_KEY: "REPLACE_ME"
  NEWS_API_KEY: "REPLACE_ME"
